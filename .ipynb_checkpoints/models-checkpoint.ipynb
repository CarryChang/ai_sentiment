{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, Dense, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105000 15000\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "val_data = pd.read_csv('data/validation.csv')\n",
    "print(len(train_data), len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>location_traffic_convenience</th>\n",
       "      <th>location_distance_from_business_district</th>\n",
       "      <th>location_easy_to_find</th>\n",
       "      <th>service_wait_time</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>service_parking_convenience</th>\n",
       "      <th>service_serving_speed</th>\n",
       "      <th>price_level</th>\n",
       "      <th>...</th>\n",
       "      <th>environment_decoration</th>\n",
       "      <th>environment_noise</th>\n",
       "      <th>environment_space</th>\n",
       "      <th>environment_cleaness</th>\n",
       "      <th>dish_portion</th>\n",
       "      <th>dish_taste</th>\n",
       "      <th>dish_look</th>\n",
       "      <th>dish_recommendation</th>\n",
       "      <th>others_overall_experience</th>\n",
       "      <th>others_willing_to_consume_again</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"4人同行 点了10个小吃\\n榴莲酥 榴莲味道不足 松软 奶味浓\\n虾饺 好吃 两颗大虾仁\\...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"之前评价了莫名其妙被删 果断继续差评！ 换了菜单 价格更低 开始砸牌子 但套餐还是有150...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"出乎意料地惊艳，椰子鸡清热降火，美容养颜，大大满足了爱吃火锅怕上火星人。椰子冻是帅帅的老板...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            content  \\\n",
       "0   0  \"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...   \n",
       "1   1  \"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...   \n",
       "2   2  \"4人同行 点了10个小吃\\n榴莲酥 榴莲味道不足 松软 奶味浓\\n虾饺 好吃 两颗大虾仁\\...   \n",
       "3   3  \"之前评价了莫名其妙被删 果断继续差评！ 换了菜单 价格更低 开始砸牌子 但套餐还是有150...   \n",
       "4   4  \"出乎意料地惊艳，椰子鸡清热降火，美容养颜，大大满足了爱吃火锅怕上火星人。椰子冻是帅帅的老板...   \n",
       "\n",
       "   location_traffic_convenience  location_distance_from_business_district  \\\n",
       "0                            -2                                        -2   \n",
       "1                            -2                                        -2   \n",
       "2                            -2                                        -2   \n",
       "3                            -2                                        -2   \n",
       "4                            -2                                        -2   \n",
       "\n",
       "   location_easy_to_find  service_wait_time  service_waiters_attitude  \\\n",
       "0                     -2                 -2                         1   \n",
       "1                     -2                 -2                        -2   \n",
       "2                     -2                 -2                         0   \n",
       "3                     -2                 -2                        -2   \n",
       "4                     -2                 -2                        -2   \n",
       "\n",
       "   service_parking_convenience  service_serving_speed  price_level  \\\n",
       "0                           -2                     -2           -2   \n",
       "1                           -2                     -2            0   \n",
       "2                           -2                      1            0   \n",
       "3                           -2                     -2            0   \n",
       "4                           -2                     -2           -2   \n",
       "\n",
       "                ...                 environment_decoration  environment_noise  \\\n",
       "0               ...                                     -2                 -2   \n",
       "1               ...                                      0                  0   \n",
       "2               ...                                     -2                 -2   \n",
       "3               ...                                     -2                 -2   \n",
       "4               ...                                     -2                 -2   \n",
       "\n",
       "   environment_space  environment_cleaness  dish_portion  dish_taste  \\\n",
       "0                 -2                    -2            -2          -2   \n",
       "1                  0                     0             1          -2   \n",
       "2                  1                    -2             0           1   \n",
       "3                 -2                    -2            -2          -1   \n",
       "4                 -2                    -2            -2           1   \n",
       "\n",
       "   dish_look  dish_recommendation  others_overall_experience  \\\n",
       "0          1                   -2                          1   \n",
       "1         -2                   -2                          1   \n",
       "2         -2                   -2                          0   \n",
       "3         -2                   -2                         -1   \n",
       "4          1                   -2                          1   \n",
       "\n",
       "   others_willing_to_consume_again  \n",
       "0                               -2  \n",
       "1                               -2  \n",
       "2                               -2  \n",
       "3                               -1  \n",
       "4                               -2  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>location_traffic_convenience</th>\n",
       "      <th>location_distance_from_business_district</th>\n",
       "      <th>location_easy_to_find</th>\n",
       "      <th>service_wait_time</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>service_parking_convenience</th>\n",
       "      <th>service_serving_speed</th>\n",
       "      <th>price_level</th>\n",
       "      <th>...</th>\n",
       "      <th>environment_decoration</th>\n",
       "      <th>environment_noise</th>\n",
       "      <th>environment_space</th>\n",
       "      <th>environment_cleaness</th>\n",
       "      <th>dish_portion</th>\n",
       "      <th>dish_taste</th>\n",
       "      <th>dish_look</th>\n",
       "      <th>dish_recommendation</th>\n",
       "      <th>others_overall_experience</th>\n",
       "      <th>others_willing_to_consume_again</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"我想说他们家的优惠活动好持久啊，我预售的时候买的券，前两天心血来潮去吃的活动还在继续\\n首...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"终于开到心心念念的LAB loft。第一次来就随便点也一些～【香辣虾意面】蛮辣的，但其实一...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"地理位置好，交通方便，就在124车站对面交通方便，很好，我晚上7点多去买的了，已经没有什么...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"运气很好，抽中了大众点评的霸王餐。这家主题餐厅心仪已久了，种种原因一直未能成行，没想到抽中...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"幸运随点评团体验霸王餐，心情好~蜀九香刚进驻泉州不久，招牌大名气响，以至于刚到店门口的我被...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            content  \\\n",
       "0   0  \"我想说他们家的优惠活动好持久啊，我预售的时候买的券，前两天心血来潮去吃的活动还在继续\\n首...   \n",
       "1   1  \"终于开到心心念念的LAB loft。第一次来就随便点也一些～【香辣虾意面】蛮辣的，但其实一...   \n",
       "2   2  \"地理位置好，交通方便，就在124车站对面交通方便，很好，我晚上7点多去买的了，已经没有什么...   \n",
       "3   3  \"运气很好，抽中了大众点评的霸王餐。这家主题餐厅心仪已久了，种种原因一直未能成行，没想到抽中...   \n",
       "4   4  \"幸运随点评团体验霸王餐，心情好~蜀九香刚进驻泉州不久，招牌大名气响，以至于刚到店门口的我被...   \n",
       "\n",
       "   location_traffic_convenience  location_distance_from_business_district  \\\n",
       "0                           NaN                                       NaN   \n",
       "1                           NaN                                       NaN   \n",
       "2                           NaN                                       NaN   \n",
       "3                           NaN                                       NaN   \n",
       "4                           NaN                                       NaN   \n",
       "\n",
       "   location_easy_to_find  service_wait_time  service_waiters_attitude  \\\n",
       "0                    NaN                NaN                       NaN   \n",
       "1                    NaN                NaN                       NaN   \n",
       "2                    NaN                NaN                       NaN   \n",
       "3                    NaN                NaN                       NaN   \n",
       "4                    NaN                NaN                       NaN   \n",
       "\n",
       "   service_parking_convenience  service_serving_speed  price_level  \\\n",
       "0                          NaN                    NaN          NaN   \n",
       "1                          NaN                    NaN          NaN   \n",
       "2                          NaN                    NaN          NaN   \n",
       "3                          NaN                    NaN          NaN   \n",
       "4                          NaN                    NaN          NaN   \n",
       "\n",
       "                ...                 environment_decoration  environment_noise  \\\n",
       "0               ...                                    NaN                NaN   \n",
       "1               ...                                    NaN                NaN   \n",
       "2               ...                                    NaN                NaN   \n",
       "3               ...                                    NaN                NaN   \n",
       "4               ...                                    NaN                NaN   \n",
       "\n",
       "   environment_space  environment_cleaness  dish_portion  dish_taste  \\\n",
       "0                NaN                   NaN           NaN         NaN   \n",
       "1                NaN                   NaN           NaN         NaN   \n",
       "2                NaN                   NaN           NaN         NaN   \n",
       "3                NaN                   NaN           NaN         NaN   \n",
       "4                NaN                   NaN           NaN         NaN   \n",
       "\n",
       "   dish_look  dish_recommendation  others_overall_experience  \\\n",
       "0        NaN                  NaN                        NaN   \n",
       "1        NaN                  NaN                        NaN   \n",
       "2        NaN                  NaN                        NaN   \n",
       "3        NaN                  NaN                        NaN   \n",
       "4        NaN                  NaN                        NaN   \n",
       "\n",
       "   others_willing_to_consume_again  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2                              NaN  \n",
       "3                              NaN  \n",
       "4                              NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['location_traffic_convenience',\n",
       "       'location_distance_from_business_district', 'location_easy_to_find',\n",
       "       'service_wait_time', 'service_waiters_attitude',\n",
       "       'service_parking_convenience', 'service_serving_speed', 'price_level',\n",
       "       'price_cost_effective', 'price_discount', 'environment_decoration',\n",
       "       'environment_noise', 'environment_space', 'environment_cleaness',\n",
       "       'dish_portion', 'dish_taste', 'dish_look', 'dish_recommendation',\n",
       "       'others_overall_experience', 'others_willing_to_consume_again'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 位置：3个，location_traffic_convenience, location_distance_from_business_district, location_easy_to_find\n",
    "- 服务：4个，service_wait_time, service_waiters_attitude, service_parking_convenience, service_serving_speed\n",
    "- 价格：3个，price_level, price_cost_effective, price_discount\n",
    "- 环境：4个，environment_decoration, environment_noise, environment_space, environment_cleaness\n",
    "- 菜品：4个，dish_portion, dish_taste, dish_look, dish_recommendation\n",
    "- 其他：2个，others_overall_experience, others_willing_to_consume_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = list(map(lambda x: x[1:-1], train_data['content']))\n",
    "x_val = list(map(lambda x: x[1:-1], val_data['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2002, 142, 346.7424380952381, 283.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = list(map(len, x_train))\n",
    "np.max(train_len), np.min(train_len), np.mean(train_len), np.median(train_len), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 195, 345.13866666666667, 281.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_len = list(map(len, x_val))\n",
    "np.max(val_len), np.min(val_len), np.mean(val_len), np.median(val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 1000\n",
    "max_words = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words, char_level=True)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "x_train = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(x_val)\n",
    "x_val = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = list(map(lambda x: x[1:-1], test_data['content']))\n",
    "sequences = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ltc = pd.get_dummies(train_data['location_traffic_convenience'])[[-2, -1, 0, 1]].values\n",
    "y_train_ldfbd = pd.get_dummies(train_data['location_distance_from_business_district'])[[-2, -1, 0, 1]].values\n",
    "y_train_letf = pd.get_dummies(train_data['location_easy_to_find'])[[-2, -1, 0, 1]].values\n",
    "\n",
    "y_train_swt = pd.get_dummies(train_data['service_wait_time'])[[-2, -1, 0, 1]].values\n",
    "y_train_swa = pd.get_dummies(train_data['service_waiters_attitude'])[[-2, -1, 0, 1]].values\n",
    "y_train_spc = pd.get_dummies(train_data['service_parking_convenience'])[[-2, -1, 0, 1]].values\n",
    "y_train_sss = pd.get_dummies(train_data['service_serving_speed'])[[-2, -1, 0, 1]].values\n",
    "\n",
    "y_train_pl = pd.get_dummies(train_data['price_level'])[[-2, -1, 0, 1]].values\n",
    "y_train_pce = pd.get_dummies(train_data['price_cost_effective'])[[-2, -1, 0, 1]].values\n",
    "y_train_pd = pd.get_dummies(train_data['price_discount'])[[-2, -1, 0, 1]].values\n",
    "\n",
    "y_train_ed = pd.get_dummies(train_data['environment_decoration'])[[-2, -1, 0, 1]].values\n",
    "y_train_en = pd.get_dummies(train_data['environment_noise'])[[-2, -1, 0, 1]].values\n",
    "y_train_es = pd.get_dummies(train_data['environment_space'])[[-2, -1, 0, 1]].values\n",
    "y_train_ec = pd.get_dummies(train_data['environment_cleaness'])[[-2, -1, 0, 1]].values\n",
    "\n",
    "y_train_dp = pd.get_dummies(train_data['dish_portion'])[[-2, -1, 0, 1]].values\n",
    "y_train_dt = pd.get_dummies(train_data['dish_taste'])[[-2, -1, 0, 1]].values\n",
    "y_train_dl = pd.get_dummies(train_data['dish_look'])[[-2, -1, 0, 1]].values\n",
    "y_train_dr = pd.get_dummies(train_data['dish_recommendation'])[[-2, -1, 0, 1]].values\n",
    "\n",
    "y_train_ooe = pd.get_dummies(train_data['others_overall_experience'])[[-2, -1, 0, 1]].values\n",
    "y_train_owtca = pd.get_dummies(train_data['others_willing_to_consume_again'])[[-2, -1, 0, 1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_ltc = pd.get_dummies(val_data['location_traffic_convenience'])[[-2, -1, 0, 1]].values\n",
    "y_val_ldfbd = pd.get_dummies(val_data['location_distance_from_business_district'])[[-2, -1, 0, 1]].values\n",
    "y_val_letf = pd.get_dummies(val_data['location_easy_to_find'])[[-2, -1, 0, 1]].values\n",
    "\n",
    "y_val_swt = pd.get_dummies(val_data['service_wait_time'])[[-2, -1, 0, 1]].values\n",
    "y_val_swa = pd.get_dummies(val_data['service_waiters_attitude'])[[-2, -1, 0, 1]].values\n",
    "y_val_spc = pd.get_dummies(val_data['service_parking_convenience'])[[-2, -1, 0, 1]].values\n",
    "y_val_sss = pd.get_dummies(val_data['service_serving_speed'])[[-2, -1, 0, 1]].values\n",
    "\n",
    "y_val_pl = pd.get_dummies(val_data['price_level'])[[-2, -1, 0, 1]].values\n",
    "y_val_pce = pd.get_dummies(val_data['price_cost_effective'])[[-2, -1, 0, 1]].values\n",
    "y_val_pd = pd.get_dummies(val_data['price_discount'])[[-2, -1, 0, 1]].values\n",
    "\n",
    "y_val_ed = pd.get_dummies(val_data['environment_decoration'])[[-2, -1, 0, 1]].values\n",
    "y_val_en = pd.get_dummies(val_data['environment_noise'])[[-2, -1, 0, 1]].values\n",
    "y_val_es = pd.get_dummies(val_data['environment_space'])[[-2, -1, 0, 1]].values\n",
    "y_val_ec = pd.get_dummies(val_data['environment_cleaness'])[[-2, -1, 0, 1]].values\n",
    "\n",
    "y_val_dp = pd.get_dummies(val_data['dish_portion'])[[-2, -1, 0, 1]].values\n",
    "y_val_dt = pd.get_dummies(val_data['dish_taste'])[[-2, -1, 0, 1]].values\n",
    "y_val_dl = pd.get_dummies(val_data['dish_look'])[[-2, -1, 0, 1]].values\n",
    "y_val_dr = pd.get_dummies(val_data['dish_recommendation'])[[-2, -1, 0, 1]].values\n",
    "\n",
    "y_val_ooe = pd.get_dummies(val_data['others_overall_experience'])[[-2, -1, 0, 1]].values\n",
    "y_val_owtca = pd.get_dummies(val_data['others_willing_to_consume_again'])[[-2, -1, 0, 1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "    model.add(Conv1D(32, 5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/3\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.2517 - acc: 0.9284 - val_loss: 0.2067 - val_acc: 0.9406\n",
      "Epoch 2/3\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.2065 - acc: 0.9399 - val_loss: 0.1936 - val_acc: 0.9438\n",
      "Epoch 3/3\n",
      "105000/105000 [==============================] - 25s 237us/step - loss: 0.1949 - acc: 0.9423 - val_loss: 0.2024 - val_acc: 0.9430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad40d01128>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = build_model()\n",
    "model1.fit(x_train, y_train_ltc, epochs=3, batch_size=64, validation_data=(x_val, y_val_ltc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "ltc_preds = model1.predict_classes(x_test)\n",
    "ltc_preds = [labels[i] for i in ltc_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 1000\n",
    "max_words = 8000\n",
    "\n",
    "x_train = list(map(lambda x: x[1:-1], train_data['content']))\n",
    "x_val = list(map(lambda x: x[1:-1], val_data['content']))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, char_level=True)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "x_train = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(x_val)\n",
    "x_val = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "x_test = list(map(lambda x: x[1:-1], test_data['content']))\n",
    "sequences = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 27s 255us/step - loss: 0.3597 - acc: 0.8742 - val_loss: 0.3249 - val_acc: 0.8807\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 26s 249us/step - loss: 0.3127 - acc: 0.8877 - val_loss: 0.3120 - val_acc: 0.8830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad69e4de80>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 64, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "\n",
    "model1.fit(x_train, y_train_ldfbd, epochs=2, batch_size=64, validation_data=(x_val, y_val_ldfbd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "ldfbd_preds = model1.predict_classes(x_test)\n",
    "ldfbd_preds = [labels[i] for i in ldfbd_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 27s 258us/step - loss: 0.3847 - acc: 0.8858 - val_loss: 0.3215 - val_acc: 0.9053\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 26s 248us/step - loss: 0.3007 - acc: 0.9078 - val_loss: 0.2916 - val_acc: 0.9101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad65e92f60>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 64, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "\n",
    "model1.fit(x_train, y_train_letf, epochs=2, batch_size=64, validation_data=(x_val, y_val_letf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "letf_preds = model1.predict_classes(x_test)\n",
    "letf_preds = [labels[i] for i in letf_preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 27s 260us/step - loss: 0.3350 - acc: 0.8927 - val_loss: 0.2963 - val_acc: 0.9020\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 26s 249us/step - loss: 0.2905 - acc: 0.9061 - val_loss: 0.2887 - val_acc: 0.9050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad66431fd0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 64, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "\n",
    "model1.fit(x_train, y_train_swt, epochs=2, batch_size=64, validation_data=(x_val, y_val_swt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "swt_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/3\n",
      "105000/105000 [==============================] - 35s 329us/step - loss: 0.5735 - acc: 0.7860 - val_loss: 0.4792 - val_acc: 0.8168\n",
      "Epoch 2/3\n",
      "105000/105000 [==============================] - 34s 322us/step - loss: 0.4498 - acc: 0.8330 - val_loss: 0.4492 - val_acc: 0.8294\n",
      "Epoch 3/3\n",
      "105000/105000 [==============================] - 34s 321us/step - loss: 0.4105 - acc: 0.8485 - val_loss: 0.4481 - val_acc: 0.8302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad678c3ba8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "\n",
    "model1.fit(x_train, y_train_swa, epochs=3, batch_size=64, validation_data=(x_val, y_val_swa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "swa_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 27s 254us/step - loss: 0.1148 - acc: 0.9643 - val_loss: 0.0883 - val_acc: 0.9725\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 25s 243us/step - loss: 0.0845 - acc: 0.9733 - val_loss: 0.0817 - val_acc: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad68ac5240>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = build_model()\n",
    "model1.fit(x_train, y_train_spc, epochs=2, batch_size=64, validation_data=(x_val, y_val_spc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "spc_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/3\n",
      "105000/105000 [==============================] - 27s 253us/step - loss: 0.3457 - acc: 0.8998 - val_loss: 0.2820 - val_acc: 0.9144\n",
      "Epoch 2/3\n",
      "105000/105000 [==============================] - 26s 243us/step - loss: 0.2484 - acc: 0.9226 - val_loss: 0.2547 - val_acc: 0.9198\n",
      "Epoch 3/3\n",
      "105000/105000 [==============================] - 26s 244us/step - loss: 0.2305 - acc: 0.9276 - val_loss: 0.2497 - val_acc: 0.9245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad6a45d4e0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = build_model()\n",
    "model1.fit(x_train, y_train_sss, epochs=3, batch_size=64, validation_data=(x_val, y_val_sss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 26s 243us/step - loss: 0.2185 - acc: 0.9316 - val_loss: 0.2540 - val_acc: 0.9247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad65d724e0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train_sss, epochs=1, batch_size=64, validation_data=(x_val, y_val_sss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "sss_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 价格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 39s 374us/step - loss: 0.6842 - acc: 0.7316 - val_loss: 0.5638 - val_acc: 0.7801\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 38s 362us/step - loss: 0.5267 - acc: 0.7989 - val_loss: 0.5417 - val_acc: 0.7925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae5d0e31d0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "\n",
    "model1.fit(x_train, y_train_pl, epochs=2, batch_size=128, validation_data=(x_val, y_val_pl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "pl_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 45s 431us/step - loss: 0.3895 - acc: 0.8676 - val_loss: 0.3476 - val_acc: 0.8802\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 45s 433us/step - loss: 0.3364 - acc: 0.8835 - val_loss: 0.3324 - val_acc: 0.8844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae5db4ca20>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_pce, epochs=2, batch_size=64, validation_data=(x_val, y_val_pce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "pce_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 45s 433us/step - loss: 0.5102 - acc: 0.8072 - val_loss: 0.4578 - val_acc: 0.8285\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 44s 419us/step - loss: 0.4419 - acc: 0.8341 - val_loss: 0.4479 - val_acc: 0.8357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae5e16d4a8>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_pd, epochs=2, batch_size=64, validation_data=(x_val, y_val_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "pd_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 46s 435us/step - loss: 0.5316 - acc: 0.8150 - val_loss: 0.4500 - val_acc: 0.8440\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 44s 423us/step - loss: 0.4447 - acc: 0.8455 - val_loss: 0.4271 - val_acc: 0.8503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae5e704c88>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_ed, epochs=2, batch_size=64, validation_data=(x_val, y_val_ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "ed_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 46s 436us/step - loss: 0.4756 - acc: 0.8364 - val_loss: 0.4012 - val_acc: 0.8589\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 44s 423us/step - loss: 0.3967 - acc: 0.8630 - val_loss: 0.4109 - val_acc: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae5ece0438>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_en, epochs=2, batch_size=64, validation_data=(x_val, y_val_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "en_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 46s 435us/step - loss: 0.6069 - acc: 0.7834 - val_loss: 0.4982 - val_acc: 0.8227\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 44s 421us/step - loss: 0.4864 - acc: 0.8270 - val_loss: 0.4908 - val_acc: 0.8264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae5f2bb048>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_es, epochs=2, batch_size=64, validation_data=(x_val, y_val_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "es_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 46s 437us/step - loss: 0.5118 - acc: 0.8286 - val_loss: 0.4223 - val_acc: 0.8553\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 45s 427us/step - loss: 0.4201 - acc: 0.8583 - val_loss: 0.4063 - val_acc: 0.8649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae5fa2b6a0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_ec, epochs=2, batch_size=64, validation_data=(x_val, y_val_ec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "ec_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 菜品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 46s 437us/step - loss: 0.7156 - acc: 0.7367 - val_loss: 0.6294 - val_acc: 0.7745\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 45s 424us/step - loss: 0.5937 - acc: 0.7832 - val_loss: 0.6100 - val_acc: 0.7777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae60006b38>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_dp, epochs=2, batch_size=64, validation_data=(x_val, y_val_dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 44s 422us/step - loss: 0.5616 - acc: 0.7933 - val_loss: 0.6062 - val_acc: 0.7797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad6630c390>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train_dp, epochs=1, batch_size=64, validation_data=(x_val, y_val_dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 44s 421us/step - loss: 0.5357 - acc: 0.8020 - val_loss: 0.5996 - val_acc: 0.7801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad6630c4e0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train_dp, epochs=1, batch_size=64, validation_data=(x_val, y_val_dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "dp_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 46s 437us/step - loss: 0.6630 - acc: 0.7150 - val_loss: 0.5837 - val_acc: 0.7466\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 45s 424us/step - loss: 0.5484 - acc: 0.7683 - val_loss: 0.5449 - val_acc: 0.7652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae605e0b38>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_dt, epochs=2, batch_size=64, validation_data=(x_val, y_val_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "dt_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 46s 439us/step - loss: 0.6511 - acc: 0.7774 - val_loss: 0.5882 - val_acc: 0.7945\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 45s 424us/step - loss: 0.5713 - acc: 0.7993 - val_loss: 0.5765 - val_acc: 0.7981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae60e0a390>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_dl, epochs=2, batch_size=64, validation_data=(x_val, y_val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "dl_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 46s 442us/step - loss: 0.3731 - acc: 0.8829 - val_loss: 0.3327 - val_acc: 0.8941\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 44s 423us/step - loss: 0.3220 - acc: 0.8994 - val_loss: 0.3256 - val_acc: 0.9007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae61418f98>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_dr, epochs=2, batch_size=64, validation_data=(x_val, y_val_dr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "dr_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/4\n",
      "105000/105000 [==============================] - 37s 352us/step - loss: 0.6448 - acc: 0.7478 - val_loss: 0.5770 - val_acc: 0.7736\n",
      "Epoch 2/4\n",
      "105000/105000 [==============================] - 35s 333us/step - loss: 0.5450 - acc: 0.7908 - val_loss: 0.5485 - val_acc: 0.7875\n",
      "Epoch 3/4\n",
      "105000/105000 [==============================] - 35s 334us/step - loss: 0.5080 - acc: 0.8074 - val_loss: 0.5981 - val_acc: 0.7661\n",
      "Epoch 4/4\n",
      "105000/105000 [==============================] - 35s 334us/step - loss: 0.4768 - acc: 0.8216 - val_loss: 0.5615 - val_acc: 0.7883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae7e2a3e80>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(32, 5, activation='relu'))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_ooe, epochs=4, batch_size=64, validation_data=(x_val, y_val_ooe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "ooe_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "105000/105000 [==============================] - 36s 347us/step - loss: 0.5428 - acc: 0.8013 - val_loss: 0.4585 - val_acc: 0.8316\n",
      "Epoch 2/2\n",
      "105000/105000 [==============================] - 34s 328us/step - loss: 0.4465 - acc: 0.8363 - val_loss: 0.4492 - val_acc: 0.8366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae7dc2dcf8>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='rmsprop',\n",
    "          metrics=['acc'])\n",
    "model1.fit(x_train, y_train_owtca, epochs=2, batch_size=64, validation_data=(x_val, y_val_owtca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-2, -1, 0, 1]\n",
    "preds = model1.predict_classes(x_test)\n",
    "owtca_preds = [labels[i] for i in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试\n",
    "\n",
    "- 位置：3个，location_traffic_convenience, location_distance_from_business_district, location_easy_to_find\n",
    "- 服务：4个，service_wait_time, service_waiters_attitude, service_parking_convenience, service_serving_speed\n",
    "- 价格：3个，price_level, price_cost_effective, price_discount\n",
    "- 环境：4个，environment_decoration, environment_noise, environment_space, environment_cleaness\n",
    "- 菜品：4个，dish_portion, dish_taste, dish_look, dish_recommendation\n",
    "- 其他：2个，others_overall_experience, others_willing_to_consume_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['location_traffic_convenience'] = ltc_preds\n",
    "test_data['location_distance_from_business_district'] = ldfbd_preds\n",
    "test_data['location_easy_to_find'] = letf_preds\n",
    "\n",
    "test_data['service_wait_time'] = swt_preds\n",
    "test_data['service_waiters_attitude'] = swa_preds\n",
    "test_data['service_parking_convenience'] = spc_preds\n",
    "test_data['service_serving_speed'] = sss_preds\n",
    "\n",
    "test_data['price_level'] = pl_preds\n",
    "test_data['price_cost_effective'] = pce_preds\n",
    "test_data['price_discount'] = pd_preds\n",
    "\n",
    "test_data['environment_decoration'] = ed_preds\n",
    "test_data['environment_noise'] = en_preds\n",
    "test_data['environment_space'] = es_preds\n",
    "test_data['environment_cleaness'] = ec_preds\n",
    "\n",
    "test_data['dish_portion'] = dp_preds\n",
    "test_data['dish_taste'] = dt_preds\n",
    "test_data['dish_look'] = dl_preds\n",
    "test_data['dish_recommendation'] = dr_preds\n",
    "\n",
    "test_data['others_overall_experience'] = ooe_preds\n",
    "test_data['others_willing_to_consume_again'] = owtca_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>location_traffic_convenience</th>\n",
       "      <th>location_distance_from_business_district</th>\n",
       "      <th>location_easy_to_find</th>\n",
       "      <th>service_wait_time</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>service_parking_convenience</th>\n",
       "      <th>service_serving_speed</th>\n",
       "      <th>price_level</th>\n",
       "      <th>...</th>\n",
       "      <th>environment_decoration</th>\n",
       "      <th>environment_noise</th>\n",
       "      <th>environment_space</th>\n",
       "      <th>environment_cleaness</th>\n",
       "      <th>dish_portion</th>\n",
       "      <th>dish_taste</th>\n",
       "      <th>dish_look</th>\n",
       "      <th>dish_recommendation</th>\n",
       "      <th>others_overall_experience</th>\n",
       "      <th>others_willing_to_consume_again</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"我想说他们家的优惠活动好持久啊，我预售的时候买的券，前两天心血来潮去吃的活动还在继续\\n首...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"终于开到心心念念的LAB loft。第一次来就随便点也一些～【香辣虾意面】蛮辣的，但其实一...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"地理位置好，交通方便，就在124车站对面交通方便，很好，我晚上7点多去买的了，已经没有什么...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"运气很好，抽中了大众点评的霸王餐。这家主题餐厅心仪已久了，种种原因一直未能成行，没想到抽中...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"幸运随点评团体验霸王餐，心情好~蜀九香刚进驻泉州不久，招牌大名气响，以至于刚到店门口的我被...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"尽管韩国烤肉店在无锡已经有很多家了，但因为味道好吃再加上在无锡很有人气，依旧挡不住新店的开...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>\"店铺在乙烯生活二区的西北角，旁边是国旅的旗舰店，门口就是红绿灯，挺好找的。因为这是两磅一的...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>\"朋友聚会来滴，这个地方真心不错哇，又能撸串，又能唱歌，还能看现场歌手演唱。最主要是可以上台...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>\"超喜欢这家的面食，经常来吃。这家风格及产品都很像京城御面，有时会怀疑是不是同一家的。面条比...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>\"广西阳朔，前一天晚上吃的特色啤酒鱼，就看到了隔壁有家螺蛳粉，第二天过来吃。个人比较喜欢粉，...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>\"蛮早之前就在人气美食看过报道这家的夜宵了，一直想来看看，终于这次来了~~\\n大概晚上10点...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>\"中秋花好月圆之夜,一家老小共八人选择此地吃团圆饭。吴中店是新店，环境干净大气\\n整洁，提前...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>\"地址：他家位于万达广场C区，也就是说面向万达广场正面左边方向的后面商铺，要从背面商铺一楼寻...</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>\"没错，我就是楼上的室友。已经告别自助三年的我曾经发誓再也不吃自助这种只有量没有质的东西。可...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>\"我亲爱的姐姐人品爆发抽中了豪华双人霸王餐，为了能吃上这一顿我还特意提前了一天从贵阳回到成都...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>\"＃试吃/体验点评＃首先还是照例感谢大众点评和商家抽中我！感谢好运气！这次想着带父皇母后来体...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>\"原价比较贵，大众点评立减17的优惠很给力，可以点豪d，两个人原价213，折后149，吃得很...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>\"原来去过一家浮力森林，就是铂金城的那家。\\n\\n但不知道从好久那家也不复存在。\\n\\n本来...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>\"首先要感谢福之源创意料理还有大众点评给予的这次机会，知道自己被抽中免费试吃的时候心情还是很...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>\"之前参与了抢购的活动，午餐和晚餐通用，每人只限一张，每张9.9元，吃烤肉自助真是便宜到家了...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>\"腾冲市区交通方便，周日晚饭上座率6成。\\n主打烤鸭和火锅。\\n本次没有点火锅，只吃了烤鸭和...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>\"本来和几个同学一起到光谷想吃东西的，可是到处都排队，然后大众搜了一下，刚好看到这家川菜，然...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>\"菜的口味偏咸，但是味道不错，量大实惠，就是服务员的态度实在不敢恭维，一副强卖的架势，非得让...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>\"去南汇玩的时候下午无聊中就想着出去吃甜品，老公的妹妹推荐的店，说是味道、环境还不错，于是我...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>\"中午过来吃饭，因为和单位很近。之前都是一直只吃碗面就好，今天来吃了次炒菜。酸菜鱼还是有点辣...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>\"这地方高峰时期都得等位，不全是因为好吃，有特色占了很大的比率。店里环境干净整洁，桌子上纸巾...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>\"分量很大。没有吃完打包了！位于大寨沟普通公交车车站附近，价格比较亲民。来过很多次。在两个套...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>\"安排了一天去银座逛街的行程，早上10点多就坐地铁过去了，早饭也没吃，想着到了银座可以早午饭...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>\"只能说这家店懂得网络营销，盲目的看大众点评真的是人云亦云，看点评来的，榆钱48，以为是本地...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>\"#昨晚去平江路压完马路经过哑巴生煎，看到旁边的这家粽子店，早有耳闻，一直想吃吃，店面挺大也...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>14970</td>\n",
       "      <td>\"环境：共两层，主要就餐区位于二楼，一楼是厨房。二层包括大厅还有蒙古包式的开放单间，还有小舞...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14971</th>\n",
       "      <td>14971</td>\n",
       "      <td>\"感谢点评抽中的试吃霸王餐\\n首先说哈位置，就在现在已经成熟火爆的九街，苏荷酒吧斜对面，吃货...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14972</th>\n",
       "      <td>14972</td>\n",
       "      <td>\"这家在长辈群体里口碑相当好\\n离家很近，爷爷奶奶有时候懒得做饭了会过来吃\\n性价比也很好，...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14973</th>\n",
       "      <td>14973</td>\n",
       "      <td>\"丁丁麻辣烫位于和义路的边上，招牌很引人关注，白色的底子，红色的丁丁麻辣烫五个大字很引人注目...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14974</th>\n",
       "      <td>14974</td>\n",
       "      <td>\"香格里拉，热情好客，带宾客如家人是香格里拉主打的招牌，但是在我看来唐山这家刚刚开业没有一两...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14975</th>\n",
       "      <td>14975</td>\n",
       "      <td>\"实在是吃不下中山三院饭堂那么难吃的伙食，于是就出去寻觅好吃的早餐，要知道一个好的早餐才能病...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>14976</td>\n",
       "      <td>\"简单的重庆小面不简单。\\n首先来说面。筋道，那是必须的，但是不硬，软Q，爽滑。量大，女孩子...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>14977</td>\n",
       "      <td>\"【环境】超有日本居酒屋的氛围～店铺不大。一共俩层。一层可以坐十二个人左右～位子有些紧。二层...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>14978</td>\n",
       "      <td>\"作为一个一个月内来了三次，一次裸蛋糕两次冰皮月饼的人。。自我感觉还是可以来说点什么的~~D...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>14979</td>\n",
       "      <td>\"同事推荐的吃早饭的地方，离婆婆家不远，但平时不会特地过来\\n唐山路公平路路口，车站旁边，不...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14980</th>\n",
       "      <td>14980</td>\n",
       "      <td>\"公司聚餐 听说这个是之前和平广场的那家 于是大家中午没吃饭就等这顿哈哈哈 去了之后果然没失...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14981</th>\n",
       "      <td>14981</td>\n",
       "      <td>\"就在步行街上，非常好找，酒店check in后就出来觅食了，9点多，店铺刚开张的感觉，好多...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14982</th>\n",
       "      <td>14982</td>\n",
       "      <td>\"在附近挑了好几家火锅店最后选中了这家～冲着专门吃牛肉火锅来的～总体感觉一般吧，都是按照招牌...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>14983</td>\n",
       "      <td>\"Enjoy上订购的双人套餐。整体来说，店内设计雅致，环境安静、食材新鲜，服务周到。\\n店门...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>14984</td>\n",
       "      <td>\"新城市广场，三楼，算是靠近电影院，大概20来米的样子\\n网上的团购，比较划算\\n首先，当时...</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14985</th>\n",
       "      <td>14985</td>\n",
       "      <td>\"今天给个四星，比之前多一星，胜在服务上。照常点了招牌的外婆红烧肉，肥而不腻，肉很大一块，很...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14986</th>\n",
       "      <td>14986</td>\n",
       "      <td>\"娜娜家的装修真的是别具风格，就连烟灰缸都那么有特点，里面放的不是土，貌似是咖啡类的东东，味...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14987</th>\n",
       "      <td>14987</td>\n",
       "      <td>\"每次都是吃完才记得拍照也是醉了(/ω＼)\\n\\n这次消费体验一般吧～因为太早去了，5点就到...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14988</th>\n",
       "      <td>14988</td>\n",
       "      <td>\"昨天和小伙伴去吃的夜宵，话说，吃撑了一餐，再去的奇葩真的很少见。\\n对于海底捞，对我来说是...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14989</th>\n",
       "      <td>14989</td>\n",
       "      <td>\"首先很感谢大众点评给的这次试吃机会，在周日的晚上和众多小伙伴们美美地聚餐！\\n捉虾记 or...</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>14990</td>\n",
       "      <td>\"888附近基本没有韩式冷面的店，好想吃，最近的也就是这家了。周五翘班过来吃。来的比较晚，都...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>14991</td>\n",
       "      <td>\"说这里性价比很高的人，一定是没有吃过六六寿司，强烈推荐六六寿司的定食套餐，绝对比这里吃的爽...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>14992</td>\n",
       "      <td>\"很幸运的中了霸王餐，上午考完试用脑过度刚好补充体力。位置还是很好找的，现在的烧烤店没点特色...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>14993</td>\n",
       "      <td>\"经常来吃的一家披萨店，珠江路和金鹰三期都有，来的金鹰的八楼，来的时候前面还有七桌，可以扫一...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>14994</td>\n",
       "      <td>\"真的不得不说，里面几个男服务员服务真的很好，很耐心！收盘子也很积极！说说菜的味道吧，总体来...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>14995</td>\n",
       "      <td>\"杭州大厦周围的日料店有三上、山葵这样的连锁店，听说三上除了C座地下一楼的那家以外还要在D座...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>14996</td>\n",
       "      <td>\"非常物美价廉的一家自助餐厅，虽是中午，之前担心的货少量不足的问题完全没出现，最爱的三文鱼、...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>14997</td>\n",
       "      <td>\"生日的时候不知道去吃什么，偶然在大牌抢购里发现了这家店～感觉团购很给力，就果断团了一份～地...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>14998</td>\n",
       "      <td>\"每次来大理都有不一样的感动，还记得上次来大理遇到一个特别好的出租车司机，这次来大理同样是这...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>14999</td>\n",
       "      <td>\"这家店位于城中湖码头，靠近广场非常近，离我们的住处比较近，开车过来只要几分钟的时间就好了。...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            content  \\\n",
       "0          0  \"我想说他们家的优惠活动好持久啊，我预售的时候买的券，前两天心血来潮去吃的活动还在继续\\n首...   \n",
       "1          1  \"终于开到心心念念的LAB loft。第一次来就随便点也一些～【香辣虾意面】蛮辣的，但其实一...   \n",
       "2          2  \"地理位置好，交通方便，就在124车站对面交通方便，很好，我晚上7点多去买的了，已经没有什么...   \n",
       "3          3  \"运气很好，抽中了大众点评的霸王餐。这家主题餐厅心仪已久了，种种原因一直未能成行，没想到抽中...   \n",
       "4          4  \"幸运随点评团体验霸王餐，心情好~蜀九香刚进驻泉州不久，招牌大名气响，以至于刚到店门口的我被...   \n",
       "5          5  \"尽管韩国烤肉店在无锡已经有很多家了，但因为味道好吃再加上在无锡很有人气，依旧挡不住新店的开...   \n",
       "6          6  \"店铺在乙烯生活二区的西北角，旁边是国旅的旗舰店，门口就是红绿灯，挺好找的。因为这是两磅一的...   \n",
       "7          7  \"朋友聚会来滴，这个地方真心不错哇，又能撸串，又能唱歌，还能看现场歌手演唱。最主要是可以上台...   \n",
       "8          8  \"超喜欢这家的面食，经常来吃。这家风格及产品都很像京城御面，有时会怀疑是不是同一家的。面条比...   \n",
       "9          9  \"广西阳朔，前一天晚上吃的特色啤酒鱼，就看到了隔壁有家螺蛳粉，第二天过来吃。个人比较喜欢粉，...   \n",
       "10        10  \"蛮早之前就在人气美食看过报道这家的夜宵了，一直想来看看，终于这次来了~~\\n大概晚上10点...   \n",
       "11        11  \"中秋花好月圆之夜,一家老小共八人选择此地吃团圆饭。吴中店是新店，环境干净大气\\n整洁，提前...   \n",
       "12        12  \"地址：他家位于万达广场C区，也就是说面向万达广场正面左边方向的后面商铺，要从背面商铺一楼寻...   \n",
       "13        13  \"没错，我就是楼上的室友。已经告别自助三年的我曾经发誓再也不吃自助这种只有量没有质的东西。可...   \n",
       "14        14  \"我亲爱的姐姐人品爆发抽中了豪华双人霸王餐，为了能吃上这一顿我还特意提前了一天从贵阳回到成都...   \n",
       "15        15  \"＃试吃/体验点评＃首先还是照例感谢大众点评和商家抽中我！感谢好运气！这次想着带父皇母后来体...   \n",
       "16        16  \"原价比较贵，大众点评立减17的优惠很给力，可以点豪d，两个人原价213，折后149，吃得很...   \n",
       "17        17  \"原来去过一家浮力森林，就是铂金城的那家。\\n\\n但不知道从好久那家也不复存在。\\n\\n本来...   \n",
       "18        18  \"首先要感谢福之源创意料理还有大众点评给予的这次机会，知道自己被抽中免费试吃的时候心情还是很...   \n",
       "19        19  \"之前参与了抢购的活动，午餐和晚餐通用，每人只限一张，每张9.9元，吃烤肉自助真是便宜到家了...   \n",
       "20        20  \"腾冲市区交通方便，周日晚饭上座率6成。\\n主打烤鸭和火锅。\\n本次没有点火锅，只吃了烤鸭和...   \n",
       "21        21  \"本来和几个同学一起到光谷想吃东西的，可是到处都排队，然后大众搜了一下，刚好看到这家川菜，然...   \n",
       "22        22  \"菜的口味偏咸，但是味道不错，量大实惠，就是服务员的态度实在不敢恭维，一副强卖的架势，非得让...   \n",
       "23        23  \"去南汇玩的时候下午无聊中就想着出去吃甜品，老公的妹妹推荐的店，说是味道、环境还不错，于是我...   \n",
       "24        24  \"中午过来吃饭，因为和单位很近。之前都是一直只吃碗面就好，今天来吃了次炒菜。酸菜鱼还是有点辣...   \n",
       "25        25  \"这地方高峰时期都得等位，不全是因为好吃，有特色占了很大的比率。店里环境干净整洁，桌子上纸巾...   \n",
       "26        26  \"分量很大。没有吃完打包了！位于大寨沟普通公交车车站附近，价格比较亲民。来过很多次。在两个套...   \n",
       "27        27  \"安排了一天去银座逛街的行程，早上10点多就坐地铁过去了，早饭也没吃，想着到了银座可以早午饭...   \n",
       "28        28  \"只能说这家店懂得网络营销，盲目的看大众点评真的是人云亦云，看点评来的，榆钱48，以为是本地...   \n",
       "29        29  \"#昨晚去平江路压完马路经过哑巴生煎，看到旁边的这家粽子店，早有耳闻，一直想吃吃，店面挺大也...   \n",
       "...      ...                                                ...   \n",
       "14970  14970  \"环境：共两层，主要就餐区位于二楼，一楼是厨房。二层包括大厅还有蒙古包式的开放单间，还有小舞...   \n",
       "14971  14971  \"感谢点评抽中的试吃霸王餐\\n首先说哈位置，就在现在已经成熟火爆的九街，苏荷酒吧斜对面，吃货...   \n",
       "14972  14972  \"这家在长辈群体里口碑相当好\\n离家很近，爷爷奶奶有时候懒得做饭了会过来吃\\n性价比也很好，...   \n",
       "14973  14973  \"丁丁麻辣烫位于和义路的边上，招牌很引人关注，白色的底子，红色的丁丁麻辣烫五个大字很引人注目...   \n",
       "14974  14974  \"香格里拉，热情好客，带宾客如家人是香格里拉主打的招牌，但是在我看来唐山这家刚刚开业没有一两...   \n",
       "14975  14975  \"实在是吃不下中山三院饭堂那么难吃的伙食，于是就出去寻觅好吃的早餐，要知道一个好的早餐才能病...   \n",
       "14976  14976  \"简单的重庆小面不简单。\\n首先来说面。筋道，那是必须的，但是不硬，软Q，爽滑。量大，女孩子...   \n",
       "14977  14977  \"【环境】超有日本居酒屋的氛围～店铺不大。一共俩层。一层可以坐十二个人左右～位子有些紧。二层...   \n",
       "14978  14978  \"作为一个一个月内来了三次，一次裸蛋糕两次冰皮月饼的人。。自我感觉还是可以来说点什么的~~D...   \n",
       "14979  14979  \"同事推荐的吃早饭的地方，离婆婆家不远，但平时不会特地过来\\n唐山路公平路路口，车站旁边，不...   \n",
       "14980  14980  \"公司聚餐 听说这个是之前和平广场的那家 于是大家中午没吃饭就等这顿哈哈哈 去了之后果然没失...   \n",
       "14981  14981  \"就在步行街上，非常好找，酒店check in后就出来觅食了，9点多，店铺刚开张的感觉，好多...   \n",
       "14982  14982  \"在附近挑了好几家火锅店最后选中了这家～冲着专门吃牛肉火锅来的～总体感觉一般吧，都是按照招牌...   \n",
       "14983  14983  \"Enjoy上订购的双人套餐。整体来说，店内设计雅致，环境安静、食材新鲜，服务周到。\\n店门...   \n",
       "14984  14984  \"新城市广场，三楼，算是靠近电影院，大概20来米的样子\\n网上的团购，比较划算\\n首先，当时...   \n",
       "14985  14985  \"今天给个四星，比之前多一星，胜在服务上。照常点了招牌的外婆红烧肉，肥而不腻，肉很大一块，很...   \n",
       "14986  14986  \"娜娜家的装修真的是别具风格，就连烟灰缸都那么有特点，里面放的不是土，貌似是咖啡类的东东，味...   \n",
       "14987  14987  \"每次都是吃完才记得拍照也是醉了(/ω＼)\\n\\n这次消费体验一般吧～因为太早去了，5点就到...   \n",
       "14988  14988  \"昨天和小伙伴去吃的夜宵，话说，吃撑了一餐，再去的奇葩真的很少见。\\n对于海底捞，对我来说是...   \n",
       "14989  14989  \"首先很感谢大众点评给的这次试吃机会，在周日的晚上和众多小伙伴们美美地聚餐！\\n捉虾记 or...   \n",
       "14990  14990  \"888附近基本没有韩式冷面的店，好想吃，最近的也就是这家了。周五翘班过来吃。来的比较晚，都...   \n",
       "14991  14991  \"说这里性价比很高的人，一定是没有吃过六六寿司，强烈推荐六六寿司的定食套餐，绝对比这里吃的爽...   \n",
       "14992  14992  \"很幸运的中了霸王餐，上午考完试用脑过度刚好补充体力。位置还是很好找的，现在的烧烤店没点特色...   \n",
       "14993  14993  \"经常来吃的一家披萨店，珠江路和金鹰三期都有，来的金鹰的八楼，来的时候前面还有七桌，可以扫一...   \n",
       "14994  14994  \"真的不得不说，里面几个男服务员服务真的很好，很耐心！收盘子也很积极！说说菜的味道吧，总体来...   \n",
       "14995  14995  \"杭州大厦周围的日料店有三上、山葵这样的连锁店，听说三上除了C座地下一楼的那家以外还要在D座...   \n",
       "14996  14996  \"非常物美价廉的一家自助餐厅，虽是中午，之前担心的货少量不足的问题完全没出现，最爱的三文鱼、...   \n",
       "14997  14997  \"生日的时候不知道去吃什么，偶然在大牌抢购里发现了这家店～感觉团购很给力，就果断团了一份～地...   \n",
       "14998  14998  \"每次来大理都有不一样的感动，还记得上次来大理遇到一个特别好的出租车司机，这次来大理同样是这...   \n",
       "14999  14999  \"这家店位于城中湖码头，靠近广场非常近，离我们的住处比较近，开车过来只要几分钟的时间就好了。...   \n",
       "\n",
       "       location_traffic_convenience  location_distance_from_business_district  \\\n",
       "0                                -2                                        -2   \n",
       "1                                -2                                        -2   \n",
       "2                                 1                                         1   \n",
       "3                                 1                                         1   \n",
       "4                                -2                                        -2   \n",
       "5                                -1                                        -2   \n",
       "6                                -2                                        -2   \n",
       "7                                -2                                        -2   \n",
       "8                                -2                                        -2   \n",
       "9                                -2                                        -2   \n",
       "10                               -2                                        -2   \n",
       "11                               -2                                        -2   \n",
       "12                               -2                                         1   \n",
       "13                               -2                                        -2   \n",
       "14                               -2                                        -2   \n",
       "15                               -2                                        -2   \n",
       "16                               -2                                        -2   \n",
       "17                               -2                                        -2   \n",
       "18                                1                                        -2   \n",
       "19                               -2                                        -2   \n",
       "20                                1                                        -2   \n",
       "21                               -2                                        -2   \n",
       "22                               -2                                        -2   \n",
       "23                               -2                                        -2   \n",
       "24                               -2                                        -2   \n",
       "25                               -2                                        -2   \n",
       "26                                1                                        -2   \n",
       "27                                1                                         1   \n",
       "28                               -2                                        -2   \n",
       "29                               -2                                        -2   \n",
       "...                             ...                                       ...   \n",
       "14970                            -2                                        -2   \n",
       "14971                            -2                                        -2   \n",
       "14972                             1                                        -2   \n",
       "14973                            -2                                        -2   \n",
       "14974                            -2                                        -2   \n",
       "14975                            -2                                        -2   \n",
       "14976                            -2                                        -2   \n",
       "14977                             1                                        -2   \n",
       "14978                            -2                                        -2   \n",
       "14979                             1                                        -2   \n",
       "14980                            -2                                        -2   \n",
       "14981                            -2                                        -2   \n",
       "14982                            -2                                        -2   \n",
       "14983                            -2                                        -2   \n",
       "14984                            -2                                         1   \n",
       "14985                            -2                                        -2   \n",
       "14986                            -2                                        -2   \n",
       "14987                            -2                                        -2   \n",
       "14988                            -2                                        -2   \n",
       "14989                            -2                                         1   \n",
       "14990                            -2                                        -2   \n",
       "14991                            -2                                        -2   \n",
       "14992                            -2                                        -2   \n",
       "14993                            -2                                        -2   \n",
       "14994                            -2                                        -2   \n",
       "14995                            -2                                        -2   \n",
       "14996                            -2                                        -2   \n",
       "14997                            -2                                        -2   \n",
       "14998                            -2                                        -2   \n",
       "14999                             1                                         1   \n",
       "\n",
       "       location_easy_to_find  service_wait_time  service_waiters_attitude  \\\n",
       "0                         -2                 -2                         1   \n",
       "1                         -2                 -2                        -2   \n",
       "2                          1                 -2                         0   \n",
       "3                         -2                 -2                         1   \n",
       "4                         -2                  0                         1   \n",
       "5                          1                 -2                         1   \n",
       "6                          1                 -2                         1   \n",
       "7                         -2                 -2                        -2   \n",
       "8                         -2                 -2                        -2   \n",
       "9                          1                 -2                        -2   \n",
       "10                        -2                 -1                         1   \n",
       "11                        -2                 -2                         1   \n",
       "12                         1                 -2                        -2   \n",
       "13                        -2                 -2                        -1   \n",
       "14                        -2                 -2                         1   \n",
       "15                        -2                 -2                         1   \n",
       "16                        -2                 -2                         1   \n",
       "17                        -2                 -2                        -2   \n",
       "18                         1                 -2                         1   \n",
       "19                        -2                 -2                        -2   \n",
       "20                        -2                 -2                         1   \n",
       "21                        -2                 -2                         1   \n",
       "22                        -2                 -2                        -1   \n",
       "23                        -2                 -2                         1   \n",
       "24                        -2                 -2                        -2   \n",
       "25                        -2                 -2                         1   \n",
       "26                        -2                 -2                        -2   \n",
       "27                        -2                 -2                        -2   \n",
       "28                        -2                 -2                        -2   \n",
       "29                        -2                 -2                        -2   \n",
       "...                      ...                ...                       ...   \n",
       "14970                     -2                 -2                        -2   \n",
       "14971                     -2                 -2                         0   \n",
       "14972                     -2                 -2                         1   \n",
       "14973                     -2                 -2                        -2   \n",
       "14974                     -2                 -2                        -1   \n",
       "14975                     -2                 -2                        -2   \n",
       "14976                     -2                 -2                         1   \n",
       "14977                     -1                 -2                         1   \n",
       "14978                     -2                 -2                         1   \n",
       "14979                     -2                 -2                         0   \n",
       "14980                     -2                 -2                         1   \n",
       "14981                      1                 -2                         1   \n",
       "14982                     -2                 -2                         1   \n",
       "14983                     -2                 -2                         1   \n",
       "14984                     -2                 -2                         1   \n",
       "14985                     -2                 -2                         1   \n",
       "14986                     -2                 -2                        -2   \n",
       "14987                     -2                 -2                         0   \n",
       "14988                     -2                 -2                         1   \n",
       "14989                      1                 -2                        -2   \n",
       "14990                     -2                 -2                        -2   \n",
       "14991                     -1                 -2                        -2   \n",
       "14992                      1                 -2                         1   \n",
       "14993                     -2                 -2                         0   \n",
       "14994                     -2                 -2                         1   \n",
       "14995                     -2                 -2                         1   \n",
       "14996                     -2                 -2                         1   \n",
       "14997                      1                 -2                         1   \n",
       "14998                     -2                 -2                         1   \n",
       "14999                     -2                 -2                        -2   \n",
       "\n",
       "       service_parking_convenience  service_serving_speed  price_level  \\\n",
       "0                               -2                     -2            0   \n",
       "1                               -2                     -2           -2   \n",
       "2                               -2                     -2            0   \n",
       "3                                1                     -2           -2   \n",
       "4                               -2                     -2           -2   \n",
       "5                               -2                     -2           -1   \n",
       "6                               -2                     -2            1   \n",
       "7                               -2                     -2           -2   \n",
       "8                               -2                     -2            0   \n",
       "9                                1                      1            0   \n",
       "10                              -2                     -2           -1   \n",
       "11                              -2                     -2           -2   \n",
       "12                              -2                     -2            0   \n",
       "13                              -2                     -2            0   \n",
       "14                              -2                     -2           -2   \n",
       "15                              -2                     -2           -2   \n",
       "16                              -2                     -2           -1   \n",
       "17                              -2                     -2            0   \n",
       "18                              -2                     -2           -2   \n",
       "19                              -2                     -2            1   \n",
       "20                              -2                     -1           -2   \n",
       "21                              -2                     -2           -2   \n",
       "22                              -2                     -1            1   \n",
       "23                              -2                     -2           -2   \n",
       "24                              -2                     -2            1   \n",
       "25                              -2                     -1           -2   \n",
       "26                              -2                     -2            1   \n",
       "27                              -2                     -2            0   \n",
       "28                              -2                     -2            0   \n",
       "29                              -2                     -2           -2   \n",
       "...                            ...                    ...          ...   \n",
       "14970                           -2                     -2           -1   \n",
       "14971                           -2                     -2           -2   \n",
       "14972                           -1                      0            0   \n",
       "14973                           -2                     -2           -2   \n",
       "14974                           -2                     -2            1   \n",
       "14975                           -2                     -2            1   \n",
       "14976                           -2                      1            0   \n",
       "14977                           -2                     -1           -1   \n",
       "14978                           -2                     -2           -2   \n",
       "14979                           -2                     -2           -2   \n",
       "14980                           -2                     -2           -2   \n",
       "14981                           -2                     -2           -2   \n",
       "14982                           -2                     -2            0   \n",
       "14983                            1                     -2           -2   \n",
       "14984                           -2                     -2           -2   \n",
       "14985                           -2                     -2           -2   \n",
       "14986                           -2                     -2           -2   \n",
       "14987                           -2                     -1            0   \n",
       "14988                           -2                     -2           -2   \n",
       "14989                           -2                     -2            0   \n",
       "14990                           -2                      0           -1   \n",
       "14991                           -2                     -2           -1   \n",
       "14992                           -2                     -2           -2   \n",
       "14993                           -2                     -2           -2   \n",
       "14994                           -2                     -2            0   \n",
       "14995                           -2                     -2            0   \n",
       "14996                           -2                     -2           -2   \n",
       "14997                           -2                     -2           -2   \n",
       "14998                           -2                     -2           -2   \n",
       "14999                           -2                     -2           -2   \n",
       "\n",
       "                    ...                 environment_decoration  \\\n",
       "0                   ...                                      0   \n",
       "1                   ...                                     -2   \n",
       "2                   ...                                     -2   \n",
       "3                   ...                                      1   \n",
       "4                   ...                                      1   \n",
       "5                   ...                                      1   \n",
       "6                   ...                                     -2   \n",
       "7                   ...                                     -2   \n",
       "8                   ...                                     -2   \n",
       "9                   ...                                     -2   \n",
       "10                  ...                                     -1   \n",
       "11                  ...                                      1   \n",
       "12                  ...                                      1   \n",
       "13                  ...                                      1   \n",
       "14                  ...                                      1   \n",
       "15                  ...                                      1   \n",
       "16                  ...                                     -2   \n",
       "17                  ...                                     -2   \n",
       "18                  ...                                      1   \n",
       "19                  ...                                     -2   \n",
       "20                  ...                                     -2   \n",
       "21                  ...                                      1   \n",
       "22                  ...                                     -2   \n",
       "23                  ...                                      1   \n",
       "24                  ...                                     -2   \n",
       "25                  ...                                     -2   \n",
       "26                  ...                                     -2   \n",
       "27                  ...                                      1   \n",
       "28                  ...                                     -2   \n",
       "29                  ...                                     -2   \n",
       "...                 ...                                    ...   \n",
       "14970               ...                                     -2   \n",
       "14971               ...                                     -2   \n",
       "14972               ...                                      0   \n",
       "14973               ...                                     -2   \n",
       "14974               ...                                     -2   \n",
       "14975               ...                                     -2   \n",
       "14976               ...                                      1   \n",
       "14977               ...                                      1   \n",
       "14978               ...                                      1   \n",
       "14979               ...                                     -2   \n",
       "14980               ...                                      1   \n",
       "14981               ...                                     -2   \n",
       "14982               ...                                     -2   \n",
       "14983               ...                                      1   \n",
       "14984               ...                                     -2   \n",
       "14985               ...                                     -2   \n",
       "14986               ...                                      1   \n",
       "14987               ...                                     -2   \n",
       "14988               ...                                      0   \n",
       "14989               ...                                     -2   \n",
       "14990               ...                                     -2   \n",
       "14991               ...                                      0   \n",
       "14992               ...                                      1   \n",
       "14993               ...                                     -2   \n",
       "14994               ...                                     -2   \n",
       "14995               ...                                      0   \n",
       "14996               ...                                     -2   \n",
       "14997               ...                                     -2   \n",
       "14998               ...                                      1   \n",
       "14999               ...                                     -2   \n",
       "\n",
       "       environment_noise  environment_space  environment_cleaness  \\\n",
       "0                     -2                 -2                     1   \n",
       "1                     -2                 -2                    -2   \n",
       "2                     -2                 -2                    -2   \n",
       "3                     -2                 -2                    -2   \n",
       "4                     -1                 -2                     1   \n",
       "5                     -2                 -2                    -2   \n",
       "6                     -2                 -2                    -2   \n",
       "7                     -2                 -2                    -2   \n",
       "8                     -2                 -2                    -2   \n",
       "9                     -2                  1                     1   \n",
       "10                    -2                 -2                    -1   \n",
       "11                    -2                  1                     1   \n",
       "12                    -2                  0                    -2   \n",
       "13                    -2                 -2                    -2   \n",
       "14                    -2                 -2                    -2   \n",
       "15                     1                  1                     1   \n",
       "16                    -2                 -2                    -2   \n",
       "17                    -2                 -2                    -1   \n",
       "18                    -2                 -2                    -2   \n",
       "19                    -2                 -2                    -2   \n",
       "20                    -2                 -2                    -2   \n",
       "21                     1                  1                     1   \n",
       "22                    -2                 -2                    -2   \n",
       "23                     1                  1                     1   \n",
       "24                    -2                 -2                    -2   \n",
       "25                    -2                 -2                     1   \n",
       "26                    -2                 -2                    -2   \n",
       "27                    -2                  0                    -2   \n",
       "28                    -2                 -2                    -2   \n",
       "29                    -2                  1                     1   \n",
       "...                  ...                ...                   ...   \n",
       "14970                 -2                 -2                    -2   \n",
       "14971                 -2                  1                     1   \n",
       "14972                 -2                  0                     1   \n",
       "14973                 -2                 -2                    -2   \n",
       "14974                 -2                 -2                    -2   \n",
       "14975                 -2                 -2                    -2   \n",
       "14976                 -2                 -2                     1   \n",
       "14977                 -2                  0                    -2   \n",
       "14978                 -2                 -2                    -2   \n",
       "14979                 -2                 -2                    -2   \n",
       "14980                 -2                 -2                    -2   \n",
       "14981                 -2                 -2                    -2   \n",
       "14982                 -2                 -2                    -2   \n",
       "14983                  1                 -2                    -2   \n",
       "14984                 -2                 -2                    -2   \n",
       "14985                 -2                 -2                    -2   \n",
       "14986                  1                 -2                    -2   \n",
       "14987                 -2                 -2                    -2   \n",
       "14988                 -2                 -2                     1   \n",
       "14989                 -2                  1                     1   \n",
       "14990                 -2                 -2                    -2   \n",
       "14991                  0                 -1                    -1   \n",
       "14992                  1                  1                     1   \n",
       "14993                 -2                 -2                    -2   \n",
       "14994                 -2                 -2                    -2   \n",
       "14995                 -2                 -2                    -2   \n",
       "14996                 -2                 -2                    -2   \n",
       "14997                 -2                 -2                    -2   \n",
       "14998                 -2                 -2                    -2   \n",
       "14999                 -2                 -2                    -2   \n",
       "\n",
       "       dish_portion  dish_taste  dish_look  dish_recommendation  \\\n",
       "0                 1           1         -2                   -2   \n",
       "1                -1           0         -2                    1   \n",
       "2                -2           1         -2                   -2   \n",
       "3                -2           1         -2                    1   \n",
       "4                -2           1         -2                   -2   \n",
       "5                 0           1         -2                    1   \n",
       "6                 1           1         -2                   -2   \n",
       "7                -2           1         -2                   -2   \n",
       "8                 1           0         -2                   -2   \n",
       "9                -2           1         -2                   -2   \n",
       "10               -2           0         -2                   -2   \n",
       "11                1           1         -2                    1   \n",
       "12                1           0         -2                   -2   \n",
       "13               -1          -1         -2                   -2   \n",
       "14                0           0         -2                   -2   \n",
       "15                1           1         -2                   -2   \n",
       "16               -2           1         -2                   -2   \n",
       "17               -2           0          1                   -2   \n",
       "18                1           1         -2                   -2   \n",
       "19               -2           0         -2                   -2   \n",
       "20               -2          -1          1                   -2   \n",
       "21               -2           0         -2                   -2   \n",
       "22                1           1         -2                    1   \n",
       "23               -2           0         -2                   -2   \n",
       "24                0           0         -2                   -2   \n",
       "25                1           1         -2                   -2   \n",
       "26                0           1         -2                    1   \n",
       "27               -2           0         -2                   -2   \n",
       "28               -1           0         -2                    1   \n",
       "29                1           1         -2                   -2   \n",
       "...             ...         ...        ...                  ...   \n",
       "14970             0           0         -2                    0   \n",
       "14971            -2           0         -2                   -2   \n",
       "14972             1           1         -2                   -2   \n",
       "14973            -2           1          1                   -2   \n",
       "14974            -1           0         -2                   -2   \n",
       "14975            -2           0         -2                   -2   \n",
       "14976             1           1         -2                   -2   \n",
       "14977            -2           0         -2                   -2   \n",
       "14978            -2          -2         -2                   -2   \n",
       "14979             1           0          1                   -2   \n",
       "14980            -2           1         -2                   -2   \n",
       "14981            -2           0         -2                   -2   \n",
       "14982            -2           0         -2                   -2   \n",
       "14983             1           1         -2                   -2   \n",
       "14984            -2           1         -2                   -2   \n",
       "14985             1           0         -2                   -2   \n",
       "14986            -2           1          1                   -2   \n",
       "14987            -2           0         -2                   -2   \n",
       "14988             1           1         -2                   -2   \n",
       "14989             0           0         -2                   -1   \n",
       "14990            -2           0         -2                   -2   \n",
       "14991            -2          -2         -2                    1   \n",
       "14992            -2           1         -2                   -2   \n",
       "14993            -2           1         -2                   -2   \n",
       "14994            -2           1         -2                   -2   \n",
       "14995            -2           1         -2                    1   \n",
       "14996             1           1         -2                   -2   \n",
       "14997            -2           0         -1                   -2   \n",
       "14998            -2           1         -2                   -2   \n",
       "14999            -2           1         -2                   -2   \n",
       "\n",
       "       others_overall_experience  others_willing_to_consume_again  \n",
       "0                              1                                1  \n",
       "1                              1                                1  \n",
       "2                              1                               -1  \n",
       "3                              1                               -2  \n",
       "4                              1                               -2  \n",
       "5                              1                               -2  \n",
       "6                              1                               -2  \n",
       "7                              1                                1  \n",
       "8                              1                               -2  \n",
       "9                              1                               -2  \n",
       "10                             1                               -2  \n",
       "11                             1                               -2  \n",
       "12                             1                               -2  \n",
       "13                            -1                               -2  \n",
       "14                             1                                1  \n",
       "15                             1                                1  \n",
       "16                             1                               -2  \n",
       "17                             0                               -2  \n",
       "18                             1                                1  \n",
       "19                             1                               -2  \n",
       "20                             0                               -1  \n",
       "21                             1                               -2  \n",
       "22                             0                               -2  \n",
       "23                             1                               -2  \n",
       "24                             1                               -2  \n",
       "25                             1                               -2  \n",
       "26                             1                               -2  \n",
       "27                             1                               -2  \n",
       "28                             1                                1  \n",
       "29                             1                               -2  \n",
       "...                          ...                              ...  \n",
       "14970                          0                               -2  \n",
       "14971                          0                               -2  \n",
       "14972                          1                                1  \n",
       "14973                          1                               -2  \n",
       "14974                         -1                               -2  \n",
       "14975                          1                                1  \n",
       "14976                          1                                1  \n",
       "14977                          1                               -2  \n",
       "14978                          1                                1  \n",
       "14979                          1                                1  \n",
       "14980                          1                               -2  \n",
       "14981                          1                                1  \n",
       "14982                          1                               -2  \n",
       "14983                          1                               -2  \n",
       "14984                          1                               -2  \n",
       "14985                          1                               -2  \n",
       "14986                          1                               -2  \n",
       "14987                          0                               -2  \n",
       "14988                          1                               -2  \n",
       "14989                          1                               -2  \n",
       "14990                          0                               -2  \n",
       "14991                          1                               -2  \n",
       "14992                          1                                1  \n",
       "14993                          1                               -2  \n",
       "14994                          0                               -2  \n",
       "14995                          1                                1  \n",
       "14996                          1                                1  \n",
       "14997                          1                               -2  \n",
       "14998                          1                                1  \n",
       "14999                          1                                1  \n",
       "\n",
       "[15000 rows x 22 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
